{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "Self-Supervision.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "id": "C03ZD0DjsKDk"
      },
      "source": [
        "# Self-Supervision with FastAI\n",
        "> A tutorial of rotation-based self-supervision using FastAI2 & PyTorch!\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-03-23T14:49:40.997471Z",
          "start_time": "2020-03-23T14:49:40.985501Z"
        },
        "heading_collapsed": true,
        "id": "dxu_w4wDsKDl"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "This notebook is an introduction to self-supervised learning. In short, self-supervised learning has 2 components:\n",
        "\n",
        "1. Pretrain on a pretext task, where the labels can come from the data itself\n",
        "2. Transfer the features, and train on the actual classification labels!\n",
        "\n",
        ">\"What if we can get labels for free for unlabelled data and train unsupervised dataset in a supervised manner? We can achieve this by framing a supervised learning task in a special form to predict only a subset of information using the rest. In this way, all the information needed, both inputs and labels, has been provided. This is known as self-supervised learning.\" - Lilian Weng\n",
        "\n",
        "Using FastAI2, we'll use rotation as a pretext task for learning representations/features of our data. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9sVI6l8hsKDm"
      },
      "source": [
        "# Experiment Layout"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3goAouG1sKDm"
      },
      "source": [
        "In this notebook, we will be using the [MNIST dataset](https://en.wikipedia.org/wiki/MNIST_database).\n",
        "\n",
        "\n",
        "1. Train a model on a rotation prediction task.\n",
        "  - We will use *all* the training data for rotation prediction.\n",
        "  - Input: A rotated image.\n",
        "  - Target/Label: Classify the amount of degrees rotated.\n",
        "  - Our model should learn useful features that can transfer well for a classification task.\n",
        "  - (The model should learn what digits look like in order to be able to successfully predict the amount of rotation).\n",
        "\n",
        "2. Transfer our rotation pretraining features to solve the classification task with *much fewer* labels, < 1% of the original data.\n",
        "  - Input: A normal image.\n",
        "  - Target/Label: The images' *original* categorical label.\n",
        "  - Classification accuracy should be decent, even with only using < 1% of the original data.\n",
        "\n",
        "3. Train a classifier from scratch on the same amount of data used in experiment 2.\n",
        "  - Input: A normal image.\n",
        "  - Target/Label: The images' *original* categorical label.\n",
        "  - Classification accuracy should be low (lack of transfer learning & too few labeled data!)\n",
        "  - Model may overfit.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sy1Sk4u0sKDn"
      },
      "source": [
        "# FastAI Vision Model Creation Methods"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJU3mprVsKDn"
      },
      "source": [
        "> Warning: This Jupyter notebook runs with fastai2! Make sure you have it installed, use the cell below to install it :)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-03-10T22:05:13.201652Z",
          "start_time": "2021-03-10T22:04:58.559155Z"
        },
        "id": "HyvfEaePsKDn"
      },
      "source": [
        "!pip install fastai --upgrade\n",
        "\n",
        "# Uncomment and run the below line to get a fresh install of fastai, if needed"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g4Hd399QsKDo"
      },
      "source": [
        "> Important: Pay attention! It's important. We will be using a small ConvNet to test our self-supervised learning method. The architecture is defined below in `simple_arch`.\n",
        "\n",
        "Note that `simple_model` takes in one argument, `pretrained`. This is to allow FastAI to pass `pretrained=True` or `pretrained=False` when creating the model body! Below are some use cases of when we would want `pretrained=True` or `pretrained=False`.\n",
        "\n",
        "1. `pretrained=False` = For training a new model on our rotation prediction task.\n",
        "2. `pretrained=True` = For transferring the learnt features from our rotation task pretraining to solve a classification task.\n",
        "3. `pretrained=False` = For training a new model from scratch on the main classification task (no transfer learning)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-03-10T23:31:11.684648Z",
          "start_time": "2021-03-10T23:31:10.265151Z"
        },
        "id": "spuA4_aFsKDo"
      },
      "source": [
        "from fastai.vision.all import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-03-10T23:31:11.693859Z",
          "start_time": "2021-03-10T23:31:11.688343Z"
        },
        "id": "KzXdSxEusKDp"
      },
      "source": [
        "#collapse-show\n",
        "def simple_model(pretrained=False):\n",
        "    # Note that FastAI will automatically cut at pooling layer for the body!\n",
        "    model = nn.Sequential(\n",
        "        nn.Conv2d(1, 4, 3, 1),\n",
        "        #you code here\n",
        "    )\n",
        "    if (pretrained):\n",
        "        print(\"Loading pretrained model...\")\n",
        "        pretrained_weights = torch.load(save_path/'rot_pretrained.pt')\n",
        "        print(model.load_state_dict(pretrained_weights))\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qedasfvxsKDp"
      },
      "source": [
        "> The follow below code snippets are examples of how FastAI creates CNNs. Every model will have a *body* and a *head*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-03-10T23:31:11.704827Z",
          "start_time": "2021-03-10T23:31:11.695745Z"
        },
        "id": "NKWQvo7UsKDp"
      },
      "source": [
        "#collapse-show\n",
        "model = create_body(arch=simple_model, pretrained=False)\n",
        "model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-03-10T23:31:11.878524Z",
          "start_time": "2021-03-10T23:31:11.872169Z"
        },
        "id": "UAzRiUBisKDq"
      },
      "source": [
        "#collapse-show\n",
        "head = create_head(nf=32, n_out=8, lin_ftrs=[]) #nf - number of features\n",
        "head"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-03-10T23:31:12.399617Z",
          "start_time": "2021-03-10T23:31:12.386435Z"
        },
        "id": "Q8JX035VsKDq"
      },
      "source": [
        "#collapse-show\n",
        "# Note that FastAI automatically determines nf for the head!\n",
        "model = create_cnn_model(arch=simple_model, pretrained=False, n_out=8, lin_ftrs=[])\n",
        "model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0FgvYTGesKDq"
      },
      "source": [
        "# PyTorch Rotation/Classification Self-Supervised Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-03-10T23:31:12.808083Z",
          "start_time": "2021-03-10T23:31:12.804890Z"
        },
        "id": "MrBdVMG7sKDr"
      },
      "source": [
        "# --- Functions to convert between Torch Tensors and PIL Images ---\n",
        "import torchvision\n",
        "tensorToImage = torchvision.transforms.ToPILImage()\n",
        "imageToTensor = torchvision.transforms.ToTensor()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-03-10T23:28:37.733862Z",
          "start_time": "2021-03-10T23:28:37.731334Z"
        },
        "id": "BUh8dL0DsKDr"
      },
      "source": [
        "#collapse-hide\n",
        "# Uncomment and run the below lines if torchvision has trouble downloading MNIST (in the next cell)\n",
        "\n",
        "# !wget -P data/MNIST/raw/ http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
        "# !wget -P data/MNIST/raw/ http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
        "# !wget -P data/MNIST/raw/ http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
        "# !wget -P data/MNIST/raw/ http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-03-10T23:31:14.084740Z",
          "start_time": "2021-03-10T23:31:14.045646Z"
        },
        "scrolled": true,
        "id": "d8TVMoyksKDr"
      },
      "source": [
        "# Download MNIST dataset from PyTorch if not downloaded already!\n",
        "#torchvision.datasets.MNIST('data/', download=True)\n",
        "torchvision.datasets.MNIST('data/', train=True, transform=None, target_transform=None, download=True)\n",
        "!mkdir data/MNIST/Processed\n",
        "!wget https://raw.githubusercontent.com/yandexdataschool/deep_vision_and_graphics/fall21/week08-self_supervision/MNIST/processed/test.pt -O data/MNIST/Processed/test.pt\n",
        "!wget https://raw.githubusercontent.com/yandexdataschool/deep_vision_and_graphics/fall21/week08-self_supervision/MNIST/processed/training.pt -O data/MNIST/Processed/training.pt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4OXLhVcsKDr"
      },
      "source": [
        "Below we define a dataset, here's the docstring:\n",
        "\n",
        "A Dataset for Rotation-based Self-Supervision! Images are rotated clockwise.\n",
        "- `file` - MNIST processed .pt file.\n",
        "- `pct` - percent of data to use\n",
        "- `classification` - False=Use rotation labels. True=Use original classification labels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-03-10T23:31:14.623324Z",
          "start_time": "2021-03-10T23:31:14.612994Z"
        },
        "id": "fZcngz6fsKDs"
      },
      "source": [
        "#collapse-hide\n",
        "class Custom_Dataset_MNIST():\n",
        "    '''\n",
        "    A Dataset for Rotation-based Self-Supervision! Images are rotated clockwise.\n",
        "    - file - MNIST processed .pt file.\n",
        "    - pct - percent of data to use\n",
        "    - classification - False=Use rotation labels. True=Use original classification labels.\n",
        "    '''\n",
        "    \n",
        "    def __init__(self, file, pct, classification):\n",
        "        \n",
        "        data = torch.load(file)\n",
        "        self.imgs = data[0]\n",
        "        self.labels = data[1]\n",
        "        self.pct = pct\n",
        "        self.classification = classification\n",
        "                    \n",
        "        slice_idx = int(len(self.imgs)*self.pct)\n",
        "        self.imgs = self.imgs[:slice_idx]\n",
        "                    \n",
        "    def __len__(self):\n",
        "        return len(self.imgs)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        img = self.imgs[idx].unsqueeze(0)\n",
        "        img = tensorToImage(img)\n",
        "        img = img.resize((32, 32), resample=1)\n",
        "        img = imageToTensor(img)\n",
        "        \n",
        "        if (not self.classification):\n",
        "            # 4 classes for rotation\n",
        "            degrees = [0, 45, 90, 135, 180, 225, 270, 315]\n",
        "            rand_choice = random.randint(0, len(degrees)-1)\n",
        "            \n",
        "            img = tensorToImage(img)\n",
        "            img = img.rotate(degrees[rand_choice])\n",
        "            img = imageToTensor(img)\n",
        "            return img, torch.tensor(rand_choice).long()\n",
        "        \n",
        "        return img, self.labels[idx]\n",
        "    \n",
        "    def show_batch(self, n=3):\n",
        "        fig, axs = plt.subplots(n, n)\n",
        "        fig.tight_layout()\n",
        "        for i in range(n):\n",
        "            for j in range(n):\n",
        "                rand_idx = random.randint(0, len(self)-1)\n",
        "                img, label = self.__getitem__(rand_idx)\n",
        "                axs[i, j].imshow(tensorToImage(img), cmap='gray')\n",
        "                if self.classification:\n",
        "                    axs[i, j].set_title('Label: {0} (Digit #{1})'.format(label.item(), label.item()))\n",
        "                else:\n",
        "                    axs[i, j].set_title('Label: {0} ({1} Degrees)'.format(label.item(), label.item()*45))\n",
        "                axs[i, j].axis('off')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ofCL7xOsKDs"
      },
      "source": [
        "# Rotation Prediction Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-03-23T16:28:12.061325Z",
          "start_time": "2020-03-23T16:28:12.055543Z"
        },
        "id": "yaG_XiAksKDs"
      },
      "source": [
        "> Important: 60k training data and 10k validation data!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-03-10T23:31:15.348643Z",
          "start_time": "2021-03-10T23:31:15.302426Z"
        },
        "id": "ayvVyBWQsKDs"
      },
      "source": [
        "import torch\n",
        "# Make rotation datasets\n",
        "train_ds = Custom_Dataset_MNIST('data/MNIST/Processed/training.pt', pct=1.0, classification=False)\n",
        "valid_ds = Custom_Dataset_MNIST('data/MNIST/Processed/test.pt', pct=1.0, classification=False)\n",
        "print('{0} Training Samples | {1} Validation Samples'.format(len(train_ds), len(valid_ds)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-03-23T16:28:42.437483Z",
          "start_time": "2020-03-23T16:28:42.431824Z"
        },
        "id": "lU5W0vp2sKDt"
      },
      "source": [
        "> Note: Notice that our labels don't correspond to digits! They correspond to the amount of degrees rotated! Specifically from this predefined set: `[0, 45, 90, 135, 180, 225, 270, 315]`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-03-10T23:31:16.188918Z",
          "start_time": "2021-03-10T23:31:15.648884Z"
        },
        "id": "dnWp5zS_sKDt"
      },
      "source": [
        "from fastai.data.core import DataLoaders\n",
        "dls = DataLoaders.from_dsets(train_ds, valid_ds).cuda()\n",
        "\n",
        "# Override the show_batch function of dls to the one used in our dataset!\n",
        "dls.show_batch = train_ds.show_batch\n",
        "\n",
        "# We have 8 classes! [0, 1, 2, 3, 4, 5, 6, 7] that correspond to the [0, 45, 90, 135, 180, 225, 270, 315] degrees of rotation.\n",
        "dls.c = 8\n",
        "\n",
        "dls.show_batch()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5cTP63psKDt"
      },
      "source": [
        "# FastAI Vision Learner [Rotation]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-03-10T23:31:16.196844Z",
          "start_time": "2021-03-10T23:31:16.191449Z"
        },
        "id": "y4x7nVG4sKDt"
      },
      "source": [
        "# Create a config for our model's head!\n",
        "rotation_head = create_head(nf=32, n_out=8, lin_ftrs=[])\n",
        "rotation_head"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-03-23T16:28:42.437483Z",
          "start_time": "2020-03-23T16:28:42.431824Z"
        },
        "id": "_GIo92KmsKDt"
      },
      "source": [
        "> Note: We want to measure `top_2_accuracy` along with regular (top_1) accuracy, because there are hard-cases where it's understandable why our model got it wrong. For example: '0' rotated 90 or 270 degrees, or '1' rotated 0 or 180 degrees. (They can look the same!)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-03-10T23:31:16.284539Z",
          "start_time": "2021-03-10T23:31:16.280697Z"
        },
        "id": "c8CB5XpxsKDu"
      },
      "source": [
        "# Top_2 accuracy is a nice metric for hard-cases:\n",
        "# - A zero rotated 90 or 270 degrees?\n",
        "# - A one rotated 0 or 180 degrees?\n",
        "# etc :P\n",
        "\n",
        "top_2_accuracy = lambda inp, targ: top_k_accuracy(inp, targ, k=2)\n",
        "top_2_accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6H_l4a9GsKDu"
      },
      "source": [
        "Here, we train a model on the rotation prediction task!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-03-10T23:31:16.593891Z",
          "start_time": "2021-03-10T23:31:16.585743Z"
        },
        "id": "osn55MnpsKDu"
      },
      "source": [
        "#collapse-show\n",
        "# Note to set a value for lin_ftrs, we use the defined config above.\n",
        "learner = cnn_learner(dls,\n",
        "                      simple_model,\n",
        "                      pretrained=False,\n",
        "                      loss_func=CrossEntropyLossFlat(),\n",
        "                      custom_head=rotation_head,\n",
        "                      metrics=[accuracy, top_2_accuracy])\n",
        "\n",
        "learner.model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-03-10T23:31:19.140895Z",
          "start_time": "2021-03-10T23:31:16.752265Z"
        },
        "scrolled": true,
        "id": "HL4xMFeNsKDu"
      },
      "source": [
        "learner.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-03-10T23:31:21.664562Z",
          "start_time": "2021-03-10T23:31:19.143280Z"
        },
        "id": "cNOUS4vOsKDu"
      },
      "source": [
        "learner.lr_find()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-03-10T23:32:22.574170Z",
          "start_time": "2021-03-10T23:31:21.666666Z"
        },
        "id": "aASKG55ssKDv"
      },
      "source": [
        "learner.fit_one_cycle(5, lr_max=3e-2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K3nDMLpdsKDv"
      },
      "source": [
        "> Important: We were able to achieve 76.2% top-1 accuracy, and 96.8% top-2 accuracy after just 5 epochs! Now we want to grab our `model` from our `Learner`, and save the body of it!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UE60AWiYsKDv"
      },
      "source": [
        "> Note: Our `model` has two components, the *body* and the *head*. `model` is a list of size 2, where `model[0]` is the body, and `model[1]` is the head!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-03-10T23:32:22.581345Z",
          "start_time": "2021-03-10T23:32:22.577015Z"
        },
        "id": "eor1JHnesKDv"
      },
      "source": [
        "# Access the body of our model\n",
        "trained_body = #your code here\n",
        "trained_body"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qEXeNAbEsKDw"
      },
      "source": [
        "> Tip: To save a model in PyTorch, save it's `state_dict` function! You can use `model.load_state_dict` to re-load the weights."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-03-10T23:32:22.589471Z",
          "start_time": "2021-03-10T23:32:22.583958Z"
        },
        "id": "krgrBiUHsKDw"
      },
      "source": [
        "# Make save directory if it doesn't exist\n",
        "save_path = Path('rotation_cps/')\n",
        "if not save_path.exists():\n",
        "    save_path.mkdir()\n",
        "\n",
        "# Save the rotation-pretraining weights of our model body\n",
        "torch.save(trained_body.state_dict(), save_path/'rot_pretrained.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I74C2TgksKDw"
      },
      "source": [
        "# Original Classification Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xDYj9G6sKDw"
      },
      "source": [
        "Now that we have pretrained our model on the rotation prediction task, we want to switch over to the original labeled data for the classification task."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w1a3AHgKsKDw"
      },
      "source": [
        "> Important: We're only using 180 samples for training!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-03-10T23:32:22.635149Z",
          "start_time": "2021-03-10T23:32:22.591062Z"
        },
        "id": "kM4f733wsKDw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9b5001d-949d-40da-c922-2079d6e12e10"
      },
      "source": [
        "# Use 0.3% classification labeled data for training!\n",
        "# Use 100% classification labeled data for validation!\n",
        "train_ds = Custom_Dataset_MNIST('data/MNIST/Processed/training.pt', pct=0.03, classification=True)\n",
        "valid_ds = Custom_Dataset_MNIST('data/MNIST/Processed/test.pt', pct=1.0, classification=True)\n",
        "print('{0} Training Samples | {1} Validation Samples'.format(len(train_ds), len(valid_ds)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "180 Training Samples | 10000 Validation Samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LPqAEKCrsKDx"
      },
      "source": [
        "> Note: Notice the labels now correspond to the digit class!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-03-10T23:32:23.187943Z",
          "start_time": "2021-03-10T23:32:22.636841Z"
        },
        "id": "swpzKpZbsKDx"
      },
      "source": [
        "from fastai.data.core import DataLoaders\n",
        "dls = DataLoaders.from_dsets(train_ds, valid_ds).cuda()\n",
        "dls.show_batch = train_ds.show_batch\n",
        "\n",
        "# We have 10 classes! One for each digit label!\n",
        "dls.c = 10\n",
        "\n",
        "dls.show_batch()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KZlEj28GsKDx"
      },
      "source": [
        "# FastAI Vision Learner [Transfer-Classification]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VigzOL2bsKDx"
      },
      "source": [
        "Here we will toggle `pretrained=True` to transfer our rotation prediction features, and train on the original 180 labeled data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-03-10T23:32:23.198800Z",
          "start_time": "2021-03-10T23:32:23.189837Z"
        },
        "id": "UerDzL7osKDx"
      },
      "source": [
        "#collapse-show\n",
        "classification_head = create_head(nf=32, n_out=10, lin_ftrs=[])\n",
        "classification_head"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZtDs11-sKDy"
      },
      "source": [
        "> Note: We have `n_out=10` because of the 10 different digit classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-03-10T23:32:23.217156Z",
          "start_time": "2021-03-10T23:32:23.201091Z"
        },
        "id": "_rc4hcQpsKDy"
      },
      "source": [
        "#collapse-show\n",
        "#retrained=True will load the saved rotation pretraining weights into our model's body!\n",
        "# See simple_arch() function definition for more details!\n",
        "learner = cnn_learner(dls,\n",
        "                      simple_model,\n",
        "                      pretrained=True,\n",
        "                      loss_func=CrossEntropyLossFlat(),\n",
        "                      custom_head=classification_head,\n",
        "                      metrics=[accuracy])\n",
        "\n",
        "learner.model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KiVz0-aWsKD0"
      },
      "source": [
        "> Tip: Freezing a model's body after transferring the weights over, allows the new head to get *calibrated* with the rest of the model!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-03-10T23:32:23.221977Z",
          "start_time": "2021-03-10T23:32:23.218810Z"
        },
        "id": "GyowD_0-sKD0"
      },
      "source": [
        "learner.freeze()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oSo33OMusKD0"
      },
      "source": [
        "> Note: Looking at the model summary, we can see that the model is frozen up to the new head! Good!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-03-10T23:32:23.254536Z",
          "start_time": "2021-03-10T23:32:23.223686Z"
        },
        "scrolled": true,
        "id": "h_GxQu3psKD0"
      },
      "source": [
        "learner.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-03-10T23:32:45.606872Z",
          "start_time": "2021-03-10T23:32:23.256375Z"
        },
        "scrolled": true,
        "id": "EuDkIVh5sKD1"
      },
      "source": [
        "learner.lr_find()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-03-10T23:33:02.517996Z",
          "start_time": "2021-03-10T23:32:45.608826Z"
        },
        "id": "0QHgabnhsKD1"
      },
      "source": [
        "learner.fit_one_cycle(10, lr_max=3e-2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "paBNfW3YsKD1"
      },
      "source": [
        "> Tip: Unfreeze the model after calibrating the new head with the transferred body, and train a little more!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-03-10T23:33:02.523201Z",
          "start_time": "2021-03-10T23:33:02.520009Z"
        },
        "id": "Ol-1m2aTsKD1"
      },
      "source": [
        "learner.unfreeze()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-03-10T23:33:02.554162Z",
          "start_time": "2021-03-10T23:33:02.524646Z"
        },
        "id": "4aqHpisjsKD1"
      },
      "source": [
        "learner.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-03-10T23:33:24.154098Z",
          "start_time": "2021-03-10T23:33:02.555750Z"
        },
        "id": "uXKjrW0psKD2"
      },
      "source": [
        "learner.lr_find()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-03-10T23:33:34.334222Z",
          "start_time": "2021-03-10T23:33:24.155898Z"
        },
        "id": "zli1srFOsKD2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "213feafc-4eaa-4d25-c22a-843649db8eb4"
      },
      "source": [
        "learner.fine_tune(5, base_lr=3e-2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>1.526008</td>\n",
              "      <td>11.387036</td>\n",
              "      <td>0.113500</td>\n",
              "      <td>00:03</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='1' class='' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      20.00% [1/5 00:03<00:12]\n",
              "    </div>\n",
              "    \n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>1.407054</td>\n",
              "      <td>11.493471</td>\n",
              "      <td>0.113500</td>\n",
              "      <td>00:03</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>\n",
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='133' class='' max='157' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      84.71% [133/157 00:02<00:00 1.3478]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pBKMoXsgsKD2"
      },
      "source": [
        "> Important: We were able to get 60.6% accuracy using transfer learning from our pretraining on the rotation prediction task!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uY-WkGcssKD2"
      },
      "source": [
        "# FastAI Vision Learner [From Sratch-Classification]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BYwFO49LsKD2"
      },
      "source": [
        "Here we train a model from scratch on the original 180 labeled data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-03-10T23:33:34.348812Z",
          "start_time": "2021-03-10T23:33:34.339252Z"
        },
        "id": "FJCUgJXssKD2"
      },
      "source": [
        "#collapse-show\n",
        "# pretrained=False, Create the same model as before, but without using the rotation pretraining weights!\n",
        "learner = cnn_learner(dls,\n",
        "                      simple_arch,\n",
        "                      pretrained=False,\n",
        "                      loss_func=CrossEntropyLossFlat(),\n",
        "                      custom_head=classification_head,\n",
        "                      metrics=[accuracy])\n",
        "\n",
        "learner.model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-03-10T23:33:34.380621Z",
          "start_time": "2021-03-10T23:33:34.350685Z"
        },
        "scrolled": true,
        "id": "Mv8oZIGvsKD3"
      },
      "source": [
        "learner.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-03-10T23:33:55.922396Z",
          "start_time": "2021-03-10T23:33:34.382215Z"
        },
        "scrolled": true,
        "id": "Tw-tfBs8sKD3"
      },
      "source": [
        "learner.lr_find()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-03-10T23:34:12.533913Z",
          "start_time": "2021-03-10T23:33:55.924291Z"
        },
        "id": "2Z6ID4R2sKD3"
      },
      "source": [
        "learner.fit_one_cycle(10, lr_max=3e-2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oGEeoT-YsKD3"
      },
      "source": [
        "> Important: We were able to only get not very high accuracy with training from scratch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHyMFVgYsKD3"
      },
      "source": [
        "# Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZgPOF7HsKD3"
      },
      "source": [
        "> Important: Using self-supervision can help learn features that can transfer to a down-stream task, such as classification! In this example, we used rotation predication as our pretext task for feature representation learning. Pretraining our model on rotation prediction prior to training for classification allowed us to achieve 60.6% accuracy, on just 0.3% of the labeled data (180 samples)! Training from scratch with the same amount of data yields an accuracy of 10.3%. The motivation for using self-supervised learning is the ability to train models with decent accuracy without the need of much labeled data!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hpwezx7KsKD4"
      },
      "source": [
        "> Note: Be sure to try other self-supervised learning methods (or perhaps find your own!) and compete on the [ImageWang Leadboard](https://github.com/fastai/imagenette#image%E7%BD%91-leaderboard)! How will model size, data difficultly, and dataset size (number of samples) affect self-supervised learning?"
      ]
    }
  ]
}